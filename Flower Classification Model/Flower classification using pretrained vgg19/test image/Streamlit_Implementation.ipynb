{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDQs3B86gnh0",
        "outputId": "00b9fe8f-bc95-46fe-f777-9a261e4f808e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"Flower Classifier ğŸŒ¸\", page_icon=\"ğŸŒ¼\", layout=\"wide\")\n",
        "\n",
        "# Load the pre-trained model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = tf.keras.models.load_model(\"/content/vgg_19_model.keras\")  # Update with your model's path\n",
        "    return model\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "# Define class names\n",
        "CLASS_NAMES = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "\n",
        "# Define the prediction function\n",
        "def predict(image):\n",
        "    img_resized = image.resize((224, 224))  # Resize image to model input size\n",
        "    img_array = np.array(img_resized) / 255.0  # Normalize image\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Predict and get confidence score\n",
        "    predictions = model.predict(img_array)\n",
        "    confidence_scores = predictions[0]\n",
        "    pred_index = np.argmax(confidence_scores)\n",
        "    pred_class = CLASS_NAMES[pred_index]\n",
        "    pred_confidence = confidence_scores[pred_index]\n",
        "\n",
        "    return pred_class, pred_confidence\n",
        "\n",
        "# Initialize session state for tracking predictions\n",
        "if \"predictions\" not in st.session_state:\n",
        "    st.session_state.predictions = []\n",
        "\n",
        "# Streamlit UI\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "        .title {\n",
        "            text-align: center;\n",
        "            font-size: 3em;\n",
        "            color: #4CAF50;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .subtitle {\n",
        "            text-align: center;\n",
        "            font-size: 1.2em;\n",
        "            margin-bottom: 20px;\n",
        "            color: #6c757d;\n",
        "        }\n",
        "        .footer {\n",
        "            text-align: center;\n",
        "            font-size: 0.9em;\n",
        "            color: #888;\n",
        "            margin-top: 50px;\n",
        "        }\n",
        "        .metric-display {\n",
        "            text-align: center;\n",
        "            font-size: 1.5em;\n",
        "            padding: 10px;\n",
        "            border: 2px solid #4CAF50;\n",
        "            border-radius: 8px;\n",
        "            color: #4CAF50;\n",
        "            margin-top: 20px;\n",
        "            background-color: #f8f8f8;\n",
        "        }\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True,\n",
        ")\n",
        "\n",
        "st.markdown('<div class=\"title\">ğŸŒ¸ Flower Classification App</div>', unsafe_allow_html=True)\n",
        "st.markdown('<div class=\"subtitle\">Upload an image to identify the type of flower!</div>', unsafe_allow_html=True)\n",
        "\n",
        "# Layout setup\n",
        "uploaded_file = st.file_uploader(\"Upload an image (JPG, JPEG, PNG)\", type=[\"jpg\", \"jpeg\", \"png\"], label_visibility=\"collapsed\")\n",
        "\n",
        "# Prediction display column\n",
        "col1, col2, col3 = st.columns([1, 2, 1])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    with col1:\n",
        "        st.markdown(\"#### Uploaded Image:\")\n",
        "        st.image(uploaded_file, caption=\"Your Image\", use_container_width=True)\n",
        "\n",
        "    # Process and predict\n",
        "    image = Image.open(uploaded_file)\n",
        "    pred_class, pred_confidence = predict(image)\n",
        "\n",
        "    # Save prediction to session state\n",
        "    st.session_state.predictions.append({\"class\": pred_class, \"confidence\": pred_confidence})\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\"#### Prediction Results:\")\n",
        "        if pred_confidence < 0.2:\n",
        "            st.warning(\"âš ï¸ The prediction confidence is too low. Please try with another image.\")\n",
        "        else:\n",
        "            st.success(f\"**Prediction:** {pred_class.capitalize()}\")\n",
        "            st.markdown(\n",
        "                f'<div class=\"metric-display\"><strong>Confidence Score:</strong> {pred_confidence:.2%}</div>',\n",
        "                unsafe_allow_html=True,\n",
        "            )\n",
        "\n",
        "# Display previous predictions\n",
        "with col3:\n",
        "    st.markdown(\"#### Previous Predictions:\")\n",
        "    if st.session_state.predictions:\n",
        "        for pred in st.session_state.predictions[::-1]:  # Show latest prediction first\n",
        "            st.markdown(\n",
        "                f\"\"\"\n",
        "                <div class=\"metric-display\">\n",
        "                    ğŸŒ¼ <strong>Class:</strong> {pred[\"class\"].capitalize()}<br>\n",
        "                    ğŸ“Š <strong>Confidence:</strong> {pred[\"confidence\"]:.2%}\n",
        "                </div>\n",
        "                \"\"\",\n",
        "                unsafe_allow_html=True,\n",
        "            )\n",
        "    else:\n",
        "        st.info(\"No predictions yet.\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <div class=\"subtitle\">\n",
        "        ğŸŒ¼ **Supported Flower Categories** ğŸŒ¼\n",
        "        <ul style=\"text-align: left; font-size: 1.1em;\">\n",
        "            <li>ğŸŒ¼ Daisy</li>\n",
        "            <li>ğŸŒ¼ Dandelion</li>\n",
        "            <li>ğŸŒ¹ Rose</li>\n",
        "            <li>ğŸŒ» Sunflower</li>\n",
        "            <li>ğŸŒ· Tulip</li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True,\n",
        ")\n",
        "\n",
        "# Footer\n",
        "st.markdown('<div class=\"footer\">Created with â¤ï¸ using Streamlit</div>', unsafe_allow_html=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy-BhCfFhlTv",
        "outputId": "f26583d3-21c8-40c7-b534-d5cc71c88bd4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMF9hbPgh0Bv",
        "outputId": "425b6c14-111c-4c44-e955-7cb4c57a6fe6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "up to date, audited 23 packages in 1s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-aNt0pOh2su",
        "outputId": "98187cae-03dd-4833-f567-5c5ddde31926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.231.180.234\n",
            "your url is: https://shiny-rings-melt.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2EHaVLeh34n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}